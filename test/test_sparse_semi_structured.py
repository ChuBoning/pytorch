# Owner(s): ["module: sparse"]
import itertools
import random
import unittest

import torch
from torch import nn

from torch.sparse.semi_structured import (
    _DTYPE_TO_SEMI_STRUCTURED_SPARSE_CONFIG,
    SparseSemiStructuredTensor,
)

from torch.testing import make_tensor

from torch.testing._internal.common_device_type import (
    dtypes,
    instantiate_device_type_tests,
)

from torch.testing._internal.common_dtype import all_types_and_complex

from torch.testing._internal.common_utils import (
    parametrize,
    run_tests,
    subtest,
    TestCase,
    TEST_WITH_ROCM
)

from torch._inductor.utils import has_triton


SEMI_STRUCTURED_SUPPORTED_DTYPES = _DTYPE_TO_SEMI_STRUCTURED_SPARSE_CONFIG.keys()

_IS_SM8X = False
if torch.cuda.is_available():
    _IS_SM8X = torch.cuda.get_device_capability(0)[0] == 8

def rand_sparse_semi_structured_mask(
    r, c, dtype=torch.float16, device="cuda", choice=None
):
    """
    This function returns a 1:2 sparse matrix of size (r, c).
    Note that this means this matrix will also be 2:4 and 4:8 sparse as well.
    """

    choices = [[0, 1], [1, 0]]
    mask_entries = [choice or random.choice(choices) for i in range(r * c // 2)]

    return (
        torch.tensor(mask_entries, dtype=dtype, device=device)
        .reshape(r, c)
        .contiguous()
    )

def rand_dense_2by4(r, c, dtype, device, choice=None):
    choices = [
        [1, 1, 0, 0],
        [1, 0, 1, 0],
        [1, 0, 0, 1],
        [0, 1, 1, 0],
        [0, 1, 0, 1],
        [0, 0, 1, 1]
    ]
    mask_entries = [choice or random.choice(choices) for i in range(r * c // 4)]
    mask = torch.tensor(mask_entries, dtype=torch.bool).view(r, c).to(device)
    dense = make_tensor(r, c, dtype=dtype, device=device)
    dense[dense == 0] = 1  # To prevent zeros except where mask applied.
    dense = dense.masked_fill(~mask, 0)
    return (dense, mask)


class TestSparseSemiStructured(TestCase):

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_mm_sparse_first_NT(self, dtype, device):
        """
        Ensure torch.mm(A_sparse, B) is correct for float16 and will throw error for int8
        Ensure torch.mm(A_sparse, B.t()) is correct
        """
        A = rand_sparse_semi_structured_mask(128, 128, dtype=dtype)
        A_sparse = SparseSemiStructuredTensor(A)

        B = torch.rand((128, 128), device=A_sparse.device).to(dtype)

        # Currently we don't support int matmul on GPU, so evaluate on CPU and copy over
        if dtype is torch.int8:
            # This should fail
            with self.assertRaisesRegex(RuntimeError, "two_four_sgemm_cutlass_dispatch_layouts"):
                sparse_result = torch.mm(A_sparse, B)

            # test transpose
            # NOTE: CUTLASS and cuSPARSELt have slightly different int8 behavior.
            # CUTLASS will output to an int32 tensor while cuSPARSELt will output to a int8 tensor
            dense_result = torch.mm(A.cpu(), B.t().cpu()).to(device, dtype=torch.int32)
            sparse_result = torch.mm(A_sparse, B.t())
            assert torch.allclose(dense_result, sparse_result, rtol=1e-3, atol=1e-3)
        else:
            dense_result = torch.mm(A, B)
            sparse_result = torch.mm(A_sparse, B)
            assert torch.allclose(dense_result, sparse_result, rtol=1e-3, atol=1e-3)
            # test transpose
            dense_result = torch.mm(A, B.t())
            sparse_result = torch.mm(A_sparse, B.t())
            assert torch.allclose(dense_result, sparse_result, rtol=1e-3, atol=1e-3)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_mm_sparse_first_T(self, dtype, device):
        """
        Ensure torch.mm(A_sparse.t(), B) throws error
        """
        A = rand_sparse_semi_structured_mask(128, 128, dtype=dtype)
        A_sparse = SparseSemiStructuredTensor(A)

        B = torch.rand((128, 128), device=A_sparse.device).to(dtype)

        with self.assertRaisesRegex(
            NotImplementedError,
            r"arg0: SparseSemiStructuredTensor\(.*transposed=True",
        ):
            torch.mm(A_sparse.t(), B)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_mm_sparse_second_T(self, dtype, device):
        """
        Ensure torch.mm(A, B_sparse.t()) is correct
        """
        B = rand_sparse_semi_structured_mask(128, 128, dtype=dtype)
        B_sparse = SparseSemiStructuredTensor(B)

        A = torch.rand((128, 128), device=B_sparse.device).to(dtype)

        # Currently we don't support int matmul on GPU, so evaluate on CPU and copy over
        if dtype is torch.int8:
            dense_result = torch.mm(A.cpu(), B.t().cpu()).to(device, dtype=torch.int32)
            sparse_result = torch.mm(A, B_sparse.t())
        else:
            dense_result = torch.mm(A, B.t())
            sparse_result = torch.mm(A, B_sparse.t())

        assert torch.allclose(dense_result, sparse_result, rtol=1e-3, atol=1e-3)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_mm_sparse_second_NT(self, dtype, device):
        """
        Ensure torch.mm(A, B_sparse) throws error
        """
        B = rand_sparse_semi_structured_mask(128, 128, dtype=dtype)
        B_sparse = SparseSemiStructuredTensor(B)

        A = torch.rand((128, 128), device=B_sparse.device).to(dtype)

        with self.assertRaisesRegex(
            NotImplementedError,
            r"arg1: SparseSemiStructuredTensor\(.*transposed=False",
        ):
            sparse_result = torch.mm(A, B_sparse)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @parametrize("inference_mode", [subtest(False), subtest(True)])
    def test_linear(self, inference_mode, device):
        """
        Test nn.Linear has the same numerics
        """
        input = torch.rand(128, 128, device=device).half()
        model = nn.Linear(128, 128).to(device).half()
        m, n = model.weight.shape
        mask = rand_sparse_semi_structured_mask(m, n, device=device, dtype=torch.bool)
        # set masked weight
        model.weight = nn.Parameter(model.weight * mask)

        dense_result = model(input)

        model.weight = nn.Parameter(SparseSemiStructuredTensor(model.weight))

        if inference_mode:
            with torch.inference_mode():
                sparse_result = model(input)
        else:
            sparse_result = model(input)

        assert torch.allclose(dense_result, sparse_result, rtol=1e-5, atol=1e-5)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    def test_values(self):
        A = rand_sparse_semi_structured_mask(128, 128)
        A_sparse = SparseSemiStructuredTensor(A)
        assert A_sparse.values().shape == (128, 64)
        assert (A_sparse.values() == 1).all()

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    def test_indices(self):
        A = rand_sparse_semi_structured_mask(128, 128)
        A_sparse = SparseSemiStructuredTensor(A)
        assert A_sparse.indices().shape == (128, 8)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_unsupported_shape(self, dtype, device):
        A = rand_sparse_semi_structured_mask(4, 4, dtype=dtype, device=device)
        with self.assertRaisesRegex(RuntimeError, "Error original_tensor.shape"):
            A_sparse = SparseSemiStructuredTensor(A)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @dtypes(*all_types_and_complex())
    def test_unsupported_dtype(self, dtype, device):
        A = rand_sparse_semi_structured_mask(128, 128, dtype=dtype, device=device)

        if dtype not in SEMI_STRUCTURED_SUPPORTED_DTYPES:
            with self.assertRaisesRegex(RuntimeError, "Error original_tensor.dtype"):
                A_sparse = SparseSemiStructuredTensor(A)
        else:
            A_sparse = SparseSemiStructuredTensor(A)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    def test_unsupported_dim(self, device):
        A = torch.rand(128, 128, 128, device=device, dtype=torch.float16)

        with self.assertRaisesRegex(RuntimeError, "Error original_tensor.dim"):
            A_sparse = SparseSemiStructuredTensor(A)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @unittest.skipIf(TEST_WITH_ROCM, "ROCm doesn't support CUTLASS")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_linear_cutlass(self, device, dtype):
        def run_test(batch_shape, m, n, k, device, dtype, dtype_out, add_bias, activation, rtol, atol):
            weight, mask = rand_dense_2by4(m, k, dtype, device)
            input = make_tensor((*batch_shape, n, k), dtype=dtype, device=device)
            bias = make_tensor((m,), dtype=dtype_out, device=device) if add_bias else None

            dtype_dense = torch.float
            input_dense = input.to(dtype_dense)
            weight_dense = weight.to(dtype_dense)
            bias_dense = bias.to(dtype_dense) if add_bias else None
            output0 = torch.nn.functional.linear(input_dense, weight_dense, bias=bias_dense)
            if activation == "relu":
                relu = torch.nn.ReLU()
                output0 = relu(output0)
            elif activation == "silu":
                silu = torch.nn.SiLU()
                output0 = silu(output0)

            weight_sparse = weight.masked_select(weight != 0).view(m, k // 2)

            output1, meta = torch._structured_sparse_linear(input, weight_sparse, mask, bias=bias, activation=activation)
            torch.testing.assert_close(output1.to(dtype_dense), output0, rtol=rtol, atol=atol)

            output1, _ = torch._structured_sparse_linear(input, weight_sparse, meta, bias=bias, activation=activation)
            torch.testing.assert_close(output1.to(dtype_dense), output0, rtol=rtol, atol=atol)

        batch_shapes = [[], [3], [3, 1]]
        dtype_out = {torch.int8: torch.int32, torch.half: torch.half, torch.bfloat16: torch.bfloat16}
        activations = [None, "relu", "silu"]
        rtol, atol = 1e-3, 1e-3
        if dtype == torch.bfloat16:
            rtol, atol = 5e-3, 5e-3
        for batch_shape, m, n, k, add_bias, activation in \
                itertools.product(batch_shapes, range(3), range(3), range(3), (False, True), activations):
            if activation == "silu" and dtype == torch.int8:
                continue  # SiLU not supported for integer inputs

            m = 2 ** m * 32
            n = 2 ** n * 32
            k = 2 ** k * 128
            run_test(batch_shape, m, n, k, device, dtype, dtype_out[dtype], add_bias, activation, rtol, atol)

    @unittest.skipIf(not _IS_SM8X, "semi-structured sparsity not supported on this library version")
    @unittest.skipIf(not has_triton(), "Test needs triton and recent GPU arch")
    @dtypes(*SEMI_STRUCTURED_SUPPORTED_DTYPES)
    def test_conversions(self, device, dtype):
        def run_test(r, c, device, dtype, meta_ref):
            dense_ref, _ = rand_dense_2by4(r, c, dtype, device)

            compressed = SparseSemiStructuredTensor(dense_ref)

            meta = compressed.indices()
            torch.testing.assert_close(meta, meta_ref, rtol=0, atol=0)

            dense = compressed.to_dense()
            torch.testing.assert_close(dense, dense_ref, rtol=0, atol=0)

        shapes = [[32, 128], [32, 256], [64, 128]]
        meta_refs = {
            (32, 128, torch.int8): torch. tensor(
                [[-296926135, -840115063, -1002140604, -370549368],
                 [-582036323, -656614178, -909226556, -924920626],
                 [1218266249, -924299703, -1924380531, -322643507],
                 [1235077577, -2065835794, -908158759, -1629647219],
                 [-829630226, -925317923, -997636887, -1807099411],
                 [-1936875895, -578269624, 1284344301, -320284435],
                 [1313793164, -665987891, -1930849144, -859251491],
                 [-907748135, -640033080, -1672880440, -286664291],
                 [-325300596, -1731929640, -371664435, -823554935],
                 [-830158612, -588674743, -909228979, -845228980],
                 [-640120612, 1229842653, -1714565735, -296841748],
                 [-1656121122, 1301146084, -1635496220, -573972772],
                 [-661026675, -305275836, -1915906872, -2070327906],
                 [-578250547, -728906680, -371266424, -1655857700],
                 [-656544615, -1629909346, 1302109677, -1932670498],
                 [-389132920, -289093180, -326853304, -1731361580],
                 [-2071340578, -1673205276, -460729266, -322122364],
                 [1322880652, -582181683, -370621363, 1221362909],
                 [1321814478, 1313720537, -728184632, -1719083810],
                 [1296668748, -572662132, 1284427417, 1240222793],
                 [-1664201340, -291976764, 1218333908, -1663245080],
                 [-1935828772, -824402610, -455570104, -993474148],
                 [-909189986, 1217982188, -1664821026, -325547539],
                 [-1806919528, -639703844, -376837687, -1915446968],
                 [-1655858018, -1913852851, -1731360700, -554900248],
                 [-1898013236, -643936787, -321010535, -556936040],
                 [-1936941588, -733176340, -841463656, -1915435815],
                 [-842102370, -321065500, 1280240093, 1153731912],
                 [1221369500, -325267772, -389772919, -288782268],
                 [1301187796, -1920166706, -1722906172, -1635129123],
                 [-1919623484, -1931678068, -1801893735, -1629562740],
                 [-557523891, -590418274, -1931175612, -723608423]],
                device=device, dtype=torch.int32),
            (32, 256, torch.int8): torch. tensor(
                [[-1798779682, -1719023140, -375612211, 1323224132, -834343271,
                  -293305204, -2065852264, -907097016],
                 [-321261874, 1317985689, -1997746531, -856843891, -655502108,
                  -1982019356, -863118188, -857813532],
                 [-561724184, -644331367, -387428967, 1305341161, -1672969015,
                  1222218953, 1288560028, -834101687],
                 [-1668440356, -862025332, -1801681708, -1798379059, -591076216,
                  1306451092, -909257592, -728981784],
                 [-455811634, -935047468, -1983340915, -724726552, -1667443636,
                  -1730883959, -1930640228, -1718320056],
                 [-1717637416, -1914090280, -1001460156, -1639655224, -381368116,
                  -305607092, -1802180476, -371963699],
                 [1305008332, -1924610855, -1729869347, -582432356, -319960632,
                  1218221197, -556479356, -997945895],
                 [-309488408, -2002875955, -572724007, -725037751, 1222217368,
                  -381358882, -560051768, -1664493075],
                 [-845619508, -829141436, -1651208488, 1155418312, -1646736184,
                  -1982927676, 1235081289, -1924298684],
                 [-589544228, -909850172, -320564068, -850488084, -857848594,
                  1233701277, -1722902066, -841163620],
                 [-1807428412, -565590903, -829822588, -913552915, -1662431779,
                  1285085672, 1212697933, -321091443],
                 [-828774067, -908491570, -573273780, -1730228796, -1651994978,
                  -304266002, -1719087479, -997357111],
                 [-1801922227, -840377203, -460460604, -322052716, 1297015950,
                  -638658167, -859267900, -454244216],
                 [-291709730, -666571634, 1324281044, -666244712, -287782498,
                  -649159096, -2064789880, -639768252],
                 [-560411436, -1662214695, 1290724589, -996226995, 1155105945,
                  -1802580855, 1145670104, -1647408916],
                 [-381363000, -1655929623, -1672553316, -554807927, -376943208,
                  -1645355555, -1722888632, 1313442281],
                 [-1664513811, -1718827812, -325203763, -1735091891, 1216627928,
                  -588407148, -2008754999, -862660132],
                 [-913513255, -2002985235, -1907799735, 1288606941, -924283187,
                  -1629692691, 1229904356, 1317924296],
                 [-1651225378, -1628550930, -638740247, 1288586473, -993080940,
                  -572683028, -829564690, -993178392],
                 [-560162580, -582099767, -1797416820, -599464744, -599226164,
                  1307084940, -577967636, -1997957907],
                 [-588657192, -589542972, -1796979560, -733438248, -862006204,
                  -828844988, -309469479, -292761916],
                 [1280236684, -557232948, 1154341188, -590833516, -858153748,
                  1233708173, -321009591, -288781092],
                 [-1999841204, -1915187640, -1983079282, -643981752, -665989554,
                  -2065830772, 1217306073, -308482584],
                 [-858219122, -1915101624, -1937191220, -1807099500, -2065131284,
                  -824648636, -287446835, -1936925544],
                 [-1931571484, 1306300126, -666252135, -934441496, -828449636,
                  1222569694, -2067494450, -599139091],
                 [1296948718, -1980838180, 1313467597, -850833847, -582136164,
                  -572734392, 1300842649, -824583100],
                 [-319951410, -577467156, -909293107, -644964979, -1656099380,
                  -1941681939, -1931180908, -325151672],
                 [-303788476, -1664165404, -1998022455, -639791890, -1986094007,
                  -326284900, -1730638648, 1237900493],
                 [-1931699047, -593965490, -656569144, 1212736750, -724969340,
                  1313361380, -372356899, 1304710809],
                 [-326570860, -381100391, 1221891144, -381039156, -644945763,
                  -1645621778, -1997746744, 1151178909],
                 [1155389774, -465244515, -308459362, -1896944498, -1932227444,
                  -287781420, 1213046504, -656487011],
                 [-376156695, -287384115, -907154980, 1150590153, -1902851938,
                  -1940985522, -655561266, -724988451]], device=device,
                dtype=torch.int32),
            (64, 128, torch.int8): torch. tensor(
                [[-1731338532, 1317981918, -733460003, -376574307],
                 [-1664160564, -573795196, -655757879, -1902254871],
                 [-908311347, -645600887, -1714565411, -291729848],
                 [1217283212, -1903584019, -572749416, -640070194],
                 [-455326484, -1668463459, -555137832, -2070290748],
                 [-1986441652, -1667393332, -658223636, -1663547319],
                 [1290637032, -856777251, -577987192, -578534323],
                 [-325260856, -1898649464, 1306446284, -1903899175],
                 [-1718773287, -638825010, 1156155724, -727823924],
                 [-1981182562, -456210290, -297476626, -293018420],
                 [-1924863783, -330478380, -724704019, 1156138212],
                 [-1983100439, -913797748, -389162551, -1646404274],
                 [-2065937960, -1987521320, -1941070611, -588649012],
                 [-1663111464, 1229884638, -2066953756, -1663460908],
                 [-1655880636, -297253752, -661746356, -656894834],
                 [-1729311000, -926660391, -825405724, -1937185575],
                 [-1802987188, -2067210872, -377173812, -1980922668],
                 [-1662479138, -1941059124, -2067493160, -381051315],
                 [1296583132, -2000059239, -560379511, 1221172428],
                 [-1729606012, -320545042, -1730654516, -840327704],
                 [-1713860899, -1655879447, -2008445364, -460397362],
                 [-1899475644, -372449906, -1714124327, -1920103284],
                 [-1924863596, -465249844, 1280237128, -1981968994],
                 [-1914837812, -1899176728, -863180658, 1324140612],
                 [-297480632, -1898346163, -665920312, 1301210332],
                 [-1633822562, -1647474354, 1280150600, -593604988],
                 [-992372402, -1991979959, -1982010904, -909211260],
                 [-1981953554, -640135452, -912995875, -2004293224],
                 [-456571827, -588474044, -1924228627, -455220019],
                 [-325498546, -825368868, -1718297528, -841028386],
                 [-925987095, -1806904092, -1897034168, -1662218547],
                 [-292664248, -370354963, -554898212, -1797350012],
                 [-371926898, -1650550583, -842740247, -590046898],
                 [-576856871, -371926563, -1920366199, 1237896408],
                 [1216972872, 1318637033, -724972130, -824653432],
                 [1302240478, 1223249092, -303266658, -459417140],
                 [-2000382772, -912488115, -388086632, -288059682],
                 [-2066178871, 1150832365, -571943858, -1796351672],
                 [-639775164, -2002940466, -992032556, -572744035],
                 [-1919363890, -909601587, -1941126007, -287421284],
                 [-309556786, -863381276, -655456184, -1981505916],
                 [-1639346996, 1238293704, -556495283, 1155321325],
                 [-1645636531, -1801937719, -1713596260, -638827292],
                 [-1998726008, -1651730295, 1150848740, -842774376],
                 [-380707619, -926298931, -1630974226, -330457383],
                 [-1983296308, -1919116818, -1935872372, -1002142524],
                 [-724772712, -289093556, -304184098, 1240259796],
                 [-572945336, -1663201971, -1630234468, 1287947401],
                 [1313463789, -1798454072, -599134756, -321001336],
                 [1285377165, -288564792, -1899046839, -1722988339],
                 [-1919332963, -935027252, -830158692, -456603427],
                 [-1896971191, -1802592567, 1222154393, -574034788],
                 [-661860984, -305345404, -1930539319, -1898019768],
                 [-1796717490, -314270584, 1154305502, 1301825924],
                 [-828580632, -1646401324, -723956499, -304509820],
                 [1296996504, -1729870627, 1296976024, -1907429816],
                 [-1807446964, -1998730084, 1154784910, -655865460],
                 [-829100658, 1279823516, -1635475772, 1153736141],
                 [1222528745, -2075338258, -293288884, -2065064371],
                 [-288500584, -397878962, -1998009139, -1645655596],
                 [-661351271, 1238126228, -2071115284, -572592755],
                 [-286401298, -1631008535, -556477228, -464613668],
                 [-460026418, 1288296937, 1317969357, -296948274],
                 [-322025272, -858878564, -1628518204, 1288457678]], device=device,
                dtype=torch.int32),
            (32, 128, torch.float16): torch. tensor(
                [[17481, -9079, -4531, -12820, 20108, -9768, -4964, -26428],
                 [-11107, -8994, -8882, -10020, -14100, -30391, -12668, -8983],
                 [17545, 20041, 18589, -14104, -30500, -5923, -9768, 18765],
                 [-13879, -10002, 18845, -31523, -26402, -5660, -25271, 19853],
                 [-10002, -15139, -12660, -14120, -30579, -9148, -10087, -4659],
                 [-24951, 20040, -29555, -8824, -26419, -15288, -8824, -11123],
                 [-7028, -11059, 20046, -10163, -4967, -29026, -10019, -24871],
                 [-8999, -8504, -13852, -9767, 19848, -13884, -5938, -4412],
                 [-29628, -8824, -15292, -5655, -9779, -29559, -5672, -12567],
                 [19908, -11058, -13874, -14114, 17485, -11188, -13874, -12898],
                 [18573, -9779, -29364, -4924, -12903, -29204, -26163, -4530],
                 [-26407, -29043, -13858, -24867, 20196, -8484, -24956, -8759],
                 [17641, -9747, -15223, -27575, -27448, 19870, -29235, -31591],
                 [-30227, -10003, 19597, -4888, -4984, -25124, -5666, -25267],
                 [-27512, -8995, -29463, -13112, -25107, -13858, 19868, -29491],
                 [-8504, -9827, -25527, -4375, -25272, -31532, -4988, -26419],
                 [-9762, -5660, -31607, -25532, -25442, -5043, -25267, -29204],
                 [-29044, -25395, 20185, -8884, -25140, 19949, -28962, -9826],
                 [18894, -14119, 20169, 20045, -25108, -25108, -29556, -11188],
                 [-26548, -8564, 19785, -8739, -30306, -4636, -12850, -4900],
                 [19844, -13884, -25394, -4456, -24932, -12604, 18636, -4964],
                 [-26404, -25266, -29539, -12580, -29484, -27442, 19854, -29300],
                 [-9058, -4372, -13874, 18584, -8508, -4468, -29292, -29476],
                 [-26472, -6948, -27572, -9762, -9139, -4450, -8508, -9010],
                 [-11186, -12924, -7031, -4916, -30652, -6936, -26419, -8468],
                 [-15283, -31523, -5656, 18636, -15207, -11112, -4899, -8499],
                 [-14136, -8994, -11112, -26232, 18584, -15143, -12840, -29228],
                 [-12647, 19529, 19598, 18924, -5667, -29368, 19534, 17604],
                 [19668, -6936, 18590, -25380, -30327, -30652, -5948, -4407],
                 [-29368, -13924, -6952, -15160, -30268, -5923, -26290, -24951],
                 [-10018, -30227, -25404, -4968, 18585, -10100, -27495, -24866],
                 [-5687, -26296, -5751, -29228, -26300, -25447, -29468, -11042]],
                device=device, dtype=torch.int16),
            (32, 256, torch.float16): torch. tensor(
                [[-13090, -13860, -27448, -26231, -8754, 20180, -6956, -14268, -4455,
                  -31604, -12732, -4476, -11188, -12663, -25444, -26412],
                 [-4402, -8807, -4903, 20110, -4392, 19672, -26210, -29207, -11036,
                  -14108, -10003, -30244, -14132, -12724, -5820, -4664],
                 [-15128, 18585, -8572, -9832, -10036, -15143, 19912, -29368, -31543,
                  -27447, -25528, 18649, -13880, -27507, -4883, 18588],
                 [-24868, -30324, -25459, -13154, -27416, -30259, -4723, -30562, -7032,
                  -9068, -9020, 19934, -29032, -4898, 18649, -5820],
                 [-25395, -13244, -5732, 20190, -24947, -29464, -30264, -11059, -26472,
                  -13240, -31523, -13842, -15204, -31672, -29460, -26220],
                 [-12643, -26227, -30484, -13075, -4540, -10040, -15282, -25020, -9068,
                  -12828, -13171, -13090, -6012, 18637, -27500, -5676],
                 [19865, -4887, -5912, 19917, 18909, -13924, -26396, -8888, -8804,
                  -25015, 19661, -12728, -13180, -29223, -8492, -15228],
                 [-31532, -5683, -27492, -27442, -4903, -12983, -8740, -11064, -11128,
                  -24856, -13875, -11124, 18888, -9747, -8546, -25399],
                 [-8500, 20036, -12904, -12652, -9907, -9075, -27496, -12824, -13112,
                  -4924, -25128, -30258, -7026, -9847, 19790, -9746],
                 [17628, -13884, -8996, -13884, -8994, -4978, -4452, -10172, 17646,
                  -13923, -13090, 18824, -13922, -25016, -4392, -9906],
                 [-11068, -15223, -27580, -8631, -13100, -25127, -8552, -25364, 19933,
                  -9752, -25367, 19608, -31591, -13175, 17625, -27506],
                 [-5811, -31538, -12647, -13863, -9016, -31511, -5820, -25268, -29026,
                  17646, -25208, -4643, 19864, -8739, -5752, -25107],
                 [-28968, 18632, -25196, 17630, -4668, -8812, -7027, -4915, -10167,
                  -30652, 18845, -29363, -25404, -14200, -13112, -6932],
                 [-27492, -27412, -4892, -12978, -4908, -5736, 20206, -10167, -26162,
                  -9060, -26290, -12836, -12664, -5820, -31507, -9763],
                 [-5756, 18925, -12663, -13940, -6931, -14259, 19694, -15202, 19789,
                  -30579, 18504, -4900, -30248, -30484, 17481, -25138],
                 [-30388, -12860, -8748, -26402, -9060, 19849, -25522, -8466, -12663,
                  -30263, -26232, -15219, -12728, -30231, -26290, 20041],
                 [-30483, -15140, -25399, -26228, -12840, 18884, -8983, -8996, 17624,
                  -24940, 18564, -8979, -11196, -11196, -13154, -12648],
                 [-6951, -8467, -13940, -30564, -9076, 19660, 19534, -8503, -28979,
                  -8979, -14104, -24868, -25364, -7027, -13095, 18824],
                 [19678, 18670, -25196, -24850, -10164, -29112, -30516, -29224, -13932,
                  -29460, -15154, -8739, -12722, -4980, -10163, -31523],
                 [-26388, -9015, -8548, -8883, -25202, -8632, -13096, -29223, -30516,
                  -30580, -9144, 19944, -26388, -9148, -31512, -12584],
                 [-14131, -26291, -4963, -26476, 17560, -24872, -27420, -11192, -11063,
                  -9764, -30652, -13164, -8487, -12604, -4723, -4468],
                 [18761, -27427, -29111, 19662, -9916, -26476, 17613, -9016, -9756,
                  -4664, 18766, 20109, -14263, -29476, -4899, -4407],
                 [-26391, 17641, -9747, 19662, -25458, -25016, -30260, -9827, -10002,
                  19688, -12659, -15155, -25127, -4632, 18574, -4708],
                 [-26484, -6952, -27427, -9148, -12596, -9836, -29560, -27575, -5652,
                  -27411, -8820, -30487, -5939, -9064, -4387, -29556],
                 [-28956, -28962, -29474, 19932, -25447, -12722, -29476, -9064, -9060,
                  -4386, -12642, 18654, -10108, 19940, -11063, 20040],
                 [-8722, -12580, 19789, -30226, -4972, -8551, -4984, -5816, 20124,
                  -15288, -8883, -8740, -5987, -12818, -9842, -25111],
                 [-4658, -29460, -4883, -8812, -9906, -4451, 17629, -7100, -4660,
                  18669, -25271, -29628, -29556, -12844, -29484, -4392],
                 [-29116, -9756, -4636, -25394, 19945, -8755, -5740, -4386, -25527,
                  18844, -30306, -4979, -14178, -5810, -29036, -29618],
                 [-13159, -29208, -10167, -14259, -29496, -6930, -10019, 18504, -30258,
                  -8979, -31548, -9143, 18653, 20121, -5682, 19908],
                 [-4915, 20041, 20041, -12983, -27576, -12852, 18644, -5815, 18585,
                  -9148, 19849, -12583, -12856, -26467, -30484, 17565],
                 [18893, -25203, -13875, -9842, 18590, -4978, -4707, -28946, -31596,
                  -27576, -29468, -4962, -24856, -12899, 18509, -10018],
                 [-26423, -29458, -30488, -9763, -5668, -25399, -13843, 17556, -29496,
                  -9011, -26408, 18888, -4658, -29219, -10004, -11063]],
                device=device, dtype=torch.int16),
            (64, 128, torch.float16): torch. tensor(
                [[-8484, -12578, -26419, 20110, -26151, 19918, -26227, -9748],
                 [-4916, -27516, -25394, -8756, -29282, -14194, -30231, -6962],
                 [17613, -5751, -13860, -9852, -5927, 19668, -29372, -5043],
                 [17548, -25363, 18574, -29047, 18921, -29300, -30260, -13944],
                 [17644, 17565, -6948, -25459, 18904, -11048, -31524, -30328],
                 [20044, -26420, -30311, -25443, -4392, -29474, -25378, 18766],
                 [-28952, -25123, 19693, -13074, 17476, 17544, -25267, -4536],
                 [-5688, -6008, -4964, -28972, -12568, 18649, -26388, -14140],
                 [-26292, -8824, -27512, -31544, -12728, -30387, -4540, -28967],
                 [-27426, -13876, -25368, -29619, -10082, -30386, -24931, -25139],
                 [18908, -31591, 19784, -30519, -26290, -13239, -15143, -30396],
                 [20100, -8466, -26392, -4892, -13842, 20196, -30243, -9768],
                 [-28963, 18665, -26152, -25267, 17485, -26300, -6967, -8980],
                 [19780, -8818, -28984, -5684, 18766, -8484, -4967, -12595],
                 [-5740, -9780, -29372, -7100, -28951, -11036, -14130, -27572],
                 [-6964, -8984, -29219, -28980, 19528, -11027, -4466, -5652],
                 [18909, -4451, -11192, -5747, -30388, 18892, 17641, -11106],
                 [-4663, -6935, -10007, -29027, -8722, -6964, -4540, -4472],
                 [-12579, -29112, -26163, -4452, -6931, 17636, -11059, 17641],
                 [-30312, 19918, -8740, -9767, -9783, -8882, -5939, -25123],
                 [17624, -8508, -8471, -31591, -25363, -4660, -29619, -8983],
                 [19948, 18505, -10044, -25384, -13852, -26156, -31540, -25383],
                 [-25208, 17485, -8820, -8828, -29364, -27506, -10098, -10024],
                 [-13876, -12839, 19934, -29052, 20196, -6951, -12595, -29560],
                 [-14132, -31532, -5756, -30227, -9016, -6948, -10162, 19854],
                 [-28968, -25011, -31548, -5815, -29624, 20100, 19533, -9058],
                 [18825, -25396, -8551, 18633, -5656, -30332, -30244, -13874],
                 [20172, -25112, -26408, -12823, -13859, -5736, -13932, -30584],
                 [-29108, -6962, -30647, -7026, -26131, -6963, -29362, -6947],
                 [-30247, -29556, -26156, -29299, -9144, -4898, -26220, -12834],
                 [-8632, -29282, 19534, -30243, -29112, -28979, -28947, -25364],
                 [-6002, -14268, -13172, 20204, -4900, -25212, -8468, -27426],
                 [-10098, -26423, -5676, -25186, -30258, -10012, -4724, -13175],
                 [-8999, -9763, -8803, -5676, -29492, -9016, -25015, 18894],
                 [-30648, -12823, 18569, 20120, -27571, -25399, -25111, -27496],
                 [-25378, 19652, 19870, 18665, -9080, -26487, -30499, -25204],
                 [-27444, -30387, -30524, -13924, -8995, -13107, -5810, -14135],
                 [-25399, 20205, -31528, 17560, 19660, -26130, -30263, -29284],
                 [-12732, -29234, -9763, -30563, -10088, -14260, -11060, -4412],
                 [-11058, -27443, -29288, -13880, -29624, -29363, -8743, -25379],
                 [-8723, -15160, 20041, -27443, -29620, -13156, -27580, -30499],
                 [19597, -9784, 19613, -4404, -4722, -29028, -12652, 19528],
                 [19869, -25140, -29287, -14268, 20201, -9746, 18654, -31668],
                 [-31671, -24887, -28946, -27506, -11112, -9906, -4403, -6072],
                 [-12920, -13180, -10100, -4660, -27495, 20116, -10092, 18892],
                 [17486, -25464, -27416, -4796, -8978, -14103, -4371, -24888],
                 [-8984, -5932, -12644, -25123, -29234, -9751, -7020, 19657],
                 [-26472, 17629, 19790, -26396, 18632, -29284, -4914, -13106],
                 [-12823, -26290, -12860, -9004, -30648, -24956, -10002, -30236],
                 [-30327, -13096, -29303, 18888, -29107, -12819, -8492, 17628],
                 [-12898, -13944, -11063, -12584, -26468, 17636, -26148, -9748],
                 [-31586, -9780, -4628, -7011, -28956, 18584, 17560, -12860],
                 [17560, -28962, -5922, -4396, 20206, -24871, -24887, -5043],
                 [-11186, -9912, -8728, -27411, -4468, -31548, -29540, -15292],
                 [-14124, -24931, -15138, -8740, -31522, -9004, -4642, 18924],
                 [-15223, 19612, -29620, -4386, -26468, -31607, -24876, 19652],
                 [-4644, -6008, -9143, -4899, -24946, 18828, 17620, -10008],
                 [-10167, 18637, -28978, -26291, -24892, -25139, -24956, 17604],
                 [-14180, -14115, -12668, -6968, -15284, -25011, -4476, -31511],
                 [-26471, -4964, 18648, -8760, -13107, 18900, -30488, -25111],
                 [20169, -31672, -29458, -28962, 18924, -4723, -31603, -8738],
                 [19934, 18820, 17613, 19864, -11052, -28964, -8492, -7090],
                 [19693, -29564, -11047, -4647, -25139, -4658, 20110, -4532],
                 [18584, -4536, 19790, -29106, -14140, 19918, -24850, 19660]],
                device=device, dtype=torch.int16),
        }
        for r, c in shapes:
            if dtype == torch.bfloat16:
                meta_ref = meta_refs[(r, c, torch.float16)]
            else:
                meta_ref = meta_refs[(r, c, dtype)]
            run_test(r, c, device, dtype, meta_ref)


instantiate_device_type_tests(TestSparseSemiStructured, globals(), only_for="cuda")

if __name__ == "__main__":
    run_tests()
